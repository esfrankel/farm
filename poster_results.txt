	recon	NLL     (per pixel)

avg:
	
1	0.1534  0.1964
2	0.1523  0.1581

1	0.1667  0.2126
4	0.1669  0.1752

1	0.1580  0.1936
8	0.1596  0.1704

botright occlusion:

1	0.0726  0.0784
2	0.0753  0.0690

1	0.0841  0.0913
4	0.1063  0.1038

1	0.0815  0.0892
8	0.0826  0.0817

topleft occlusion:

1	0.0486  0.0553
2	0.0445  0.0413

1	0.0844  0.0896
4	0.0690  0.0626

1	0.0582  0.0668
8	0.0538  0.0552


Each trial was run as 1 ordering vs k orderings on the same image set with the same occlusions.  There is a decent amount of variance from trial to trial among the 1-ordering cases, which means the test set is still small to compare between trials (it is 50 occlusions * 25 images per occlusion for each trial).  However, we can still reasonably make the comparisons within trials (i.e. between each pair of the 1 ordering vs k ordering case).


avg:

recon	NLL
2 ~< 1	2 < 1
4 ~ 1	4 < 1
1 ~< 8	8 < 1

botright:

recon	NLL
1 ~< 2	2 < 1
1 < 4	1 < 4
1 ~< 8	8 < 1

topleft:

recon	NLL
2 < 1	2 < 1
4 < 1	4 < 1
8 < 1	8 < 1

(NLL on the last one is odd)


old results for 8:

avg
1	0.1551  0.1898
8	0.1531  0.2267
topleft
1	0.0728  0.0784
8	0.0768  0.1089
botright
1	0.1012  0.1048
8	0.0798  0.1130




python old_train.py -q=1000,1000 -s=1 -o=1 -m=mnist_1



NEW RESULTS FOR PAPER BELOW

Results in avg case:
dec9_1_normal:	0.18233042868721736		0.18317718130114582
dec9_2_normal:	0.16414419358794569		0.1790583273795018
dec9_4_normal:	0.16049323125972909		0.18519399315402255
dec9_8_normal:	0.16021559158871324		0.1895844344897803
dec9_1_multi:	0.18121072851650363		0.184438036067487
dec9_2_multi:	0.17191133112705234		0.18563834798644674
dec9_4_multi:	0.17572849057149945		0.198462370066709
dec9_8_multi:	0.18770498160860588		0.2019160220860992
dec9_1_kl:		0.18238381682121393		0.180094785301216
dec9_2_kl:		0.17094589105600339		0.1860326532711646
dec9_4_kl:		0.17209933685490297		0.19976480651406536
dec9_8_kl:		0.18523730169752287		0.209679276600339

Results in botright case:
dec9_1_normal:	0.0922952357433392		0.08215206157233532
dec9_2_normal:	0.09284474042376313		0.09006889303482236
dec9_4_normal:	0.08810491552254493		0.09564749570406889
dec9_8_normal:	0.08805621697451972		0.09676057182411814
dec9_1_multi:	0.09236432248403363		0.08374682541058592
dec9_2_multi:	0.09511498350291056		0.08984126556297246
dec9_4_multi:	0.09790907366705466		0.10359739182650768
dec9_8_multi:	0.10475746596285815		0.11148135404043596
dec9_1_kl:		0.09241109726069116		0.08327405608979176
dec9_2_kl:		0.09737672803395511		0.0927237247586588
dec9_4_kl:		0.09730903470082128		0.10528765415822587
dec9_8_kl:		0.10728268019990499		0.11276585297313124

Results in topleft case:
dec9_1_normal:	0.083685513657343		0.07288267737656844
dec9_2_normal:	0.06477046674007064		0.06320265483490309
dec9_4_normal:	0.05954035821634074		0.0666536976831971
dec9_8_normal:	0.06144893244851122		0.06802312654825156
dec9_1_multi:	0.08541533618889739		0.07244250625655824
dec9_2_multi:	0.06632089962958349		0.06907793476542652
dec9_4_multi:	0.06908732948485376		0.07441450321943556
dec9_8_multi:	0.07055877180580473		0.07125295250507219
dec9_1_kl:		0.0843661998829309		0.07280607152246774
dec9_2_kl:		0.06605321376984057		0.07104768511683941
dec9_4_kl:		0.06677252803052366		0.07094781400225741
dec9_8_kl:		0.07009570793892		0.07537949189655747


FORMATTED NICELY:


Results in avg case:
dec9_1_normal:	0.1823		0.1832
dec9_2_normal:	0.1641		0.1791
dec9_4_normal:	0.1605		0.1852
dec9_8_normal:	0.1602		0.1896
dec9_2_multi:	0.1719		0.1856
dec9_4_multi:	0.1757		0.1985
dec9_8_multi:	0.1877		0.2019
dec9_2_kl:		0.1709		0.1860
dec9_4_kl:		0.1721		0.1998
dec9_8_kl:		0.1852		0.2097

Results in botright case:
dec9_1_normal:	0.0923		0.0822
dec9_2_normal:	0.0928		0.0901
dec9_4_normal:	0.0881		0.0956
dec9_8_normal:	0.0881		0.0968
dec9_2_multi:	0.0951		0.0898
dec9_4_multi:	0.0979		0.1036
dec9_8_multi:	0.1048		0.1115
dec9_2_kl:		0.0974		0.0927
dec9_4_kl:		0.0973		0.1053
dec9_8_kl:		0.1073		0.1128

Results in topleft case:
dec9_1_normal:	0.0837		0.0729
dec9_2_normal:	0.0648		0.0632
dec9_4_normal:	0.0595		0.0667
dec9_8_normal:	0.0614		0.0680
dec9_2_multi:	0.0663		0.0691
dec9_4_multi:	0.0691		0.0744
dec9_8_multi:	0.0706		0.0713
dec9_2_kl:		0.0661		0.0710
dec9_4_kl:		0.0668		0.0709
dec9_8_kl:		0.0701		0.0754